{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "import shared_info\n",
    "from algos.functions import packet_error_probability\n",
    "from envs.graph import Graph\n",
    "from envs.graph_helper import import_oil_graph\n",
    "from agent.Attrition_Agent import A_AttritionGathering_Agent, Dec_AttritionGathering_Agent, Global_AttritionGathering_Agent, Greedy_AttritionGathering_Agent, Reset_AttritionGathering_Agent\n",
    "from copy import deepcopy\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams.update({'pdf.fonttype': 42})\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.set_theme(context='paper', style='white', palette='deep', font='Times New Roman', font_scale=2, color_codes=True, rc=None)\n",
    "\n",
    "distance = [i for i in range(0, 21)]\n",
    "wind = [2.5, 5, 7.5, 10]\n",
    "df_err = pd.DataFrame()\n",
    "\n",
    "for w in wind:\n",
    "    df = pd.DataFrame(data={'distance': distance, 'err': [packet_error_probability(i, w) for i in distance], 'wind': [w for _ in distance]})\n",
    "    df_err = pd.concat([df_err, df], ignore_index=True)\n",
    "\n",
    "ax = sns.pointplot(data=df_err, x='distance', y='err', hue='wind', markers=['x', 'D', 'o', 's'], palette=['b', 'g', 'r', 'skyblue'], linewidth=4)\n",
    "ax.set_xlabel(\"Distance (km)\")\n",
    "ax.set_ylabel(\"Transmission Error Rate\")\n",
    "ax.set_xticks([0, 5, 10, 15, 20])\n",
    "ax.legend(title='Wind speed (m/s)', frameon=True)\n",
    "# fig.savefig(\"../../Figure/trans_err.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log file for printing output.\n",
    "print_output = logging.getLogger('print_output')\n",
    "print_output.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(message)s')\n",
    "file_handler = logging.FileHandler('../../Data/print_output.txt')\n",
    "file_handler.setFormatter(formatter)\n",
    "print_output.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System parameters.\n",
    "xL = 0                                           # min of the x-axis.\n",
    "xH = 200                                         # max of the x-axis.\n",
    "yL = 0                                           # min of the y-axis.\n",
    "yH = 100                                         # max of the y-axis.\n",
    "obsMask=np.array([[1,1,1,1,1,1,1,1],\n",
    "                [0,1,1,1,1,1,1,1],\n",
    "                [0,0,0,1,1,1,1,0],\n",
    "                [0,0,0,0,0,0,0,0],\n",
    "                [0,0,0,0,0,0,0,0],\n",
    "                [0,0,0,0,0,0,0,0],\n",
    "                [0,0,0,0,0,0,0,0]])\n",
    "agents = [100, 70]                               # agent starting position.\n",
    "\n",
    "# Fixed parameters.\n",
    "reward_radius = 2.5                               # reward disk radius (km).\n",
    "N_components = 10                                 # number of components to be communicated.\n",
    "N_comms_every = 10                                # period of tree compression.\n",
    "c_p = 0.4                                         # Exploration parameter\n",
    "gamma = 0.7                                       # discounting factor for d-ucb.\n",
    "\n",
    "# Shared variational parameters.\n",
    "budget = 200                                      # km.\n",
    "planning_time = 60                                # (seconds).\n",
    "n_agents = 20                                     # number of agents.\n",
    "n_rewards = 200                                   # number of rewards.\n",
    "attrition_intensity = 0.5                         # proportion of agents fail.\n",
    "\n",
    "# A-MCTS.\n",
    "msg_threshold = 1\n",
    "\n",
    "# Initialise a seed for reproductivity.\n",
    "rng =  np.random.default_rng(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the motion graph files.\n",
    "G = Graph(xL, xH, yL, yH, reward_radius, obsMask)\n",
    "G.add_node(agents[0], agents[1])\n",
    "G, locs = import_oil_graph(G, n_rewards)\n",
    "\n",
    "# Add reward.\n",
    "rewards = rng.choice(locs, size=n_rewards, replace=False)\n",
    "G.reset_reward(n_rewards)\n",
    "G.add_reward(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot environment.\n",
    "mpl.style.use('seaborn-v0_8-white')\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "img = plt.imread(\"../../Data/config/map.jpg\")\n",
    "ax.imshow(img, extent=[0, 200, 0, 100])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])\n",
    "plt.xlim(0, 200)\n",
    "plt.ylim(0, 100)\n",
    "# G.draw_edges()\n",
    "# G.draw_nodes()\n",
    "G.draw_agents([agents])\n",
    "# G.draw_rewards(rewards)\n",
    "for loc in locs:\n",
    "    if loc in rewards:\n",
    "        circle = plt.Circle((loc[0], loc[1]), 2.5, fc='none', ec='r', lw=1.5)\n",
    "        plt.gca().add_patch(circle)\n",
    "    plt.scatter(loc[0], loc[1], s=10, fc='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm under testing\n",
    "mode = 'A'\n",
    "\n",
    "# Generate list of agents that will fail and the timestamp.\n",
    "attrition_idx = rng.choice(range(n_agents), size=int(n_agents*attrition_intensity), replace=False)\n",
    "attrition_time = {key: None for key in range(n_agents)}\n",
    "for item in attrition_idx:\n",
    "    attrition_time[item] = rng.random()*budget\n",
    "\n",
    "# Create robots.\n",
    "initial_actions = []\n",
    "for j in range(len(G.edges_list)):\n",
    "    if G.edges_list[j][0] == 0:\n",
    "        initial_actions.append(j)\n",
    "\n",
    "robots = list()\n",
    "for i in range(n_agents):\n",
    "    if mode == \"Dec\":\n",
    "        robots.append(Dec_AttritionGathering_Agent(initial_state=np.nan, initial_actions=deepcopy(initial_actions), initial_position=deepcopy(agents), i=i, n_agents=n_agents, gamma=gamma, c_p=c_p, budget=budget, planning_time=planning_time, N_components=N_components, N_com_every=N_comms_every, Z=deepcopy(G), n_rewards=n_rewards, logger=print_output, fail_conidtion=attrition_time[i]))\n",
    "    elif mode == \"A\":\n",
    "        robots.append(A_AttritionGathering_Agent(initial_state=np.nan, initial_actions=deepcopy(initial_actions), initial_position=deepcopy(agents), i=i, n_agents=n_agents, gamma=gamma, c_p=c_p, budget=budget, planning_time=planning_time, N_components=N_components, N_com_every=N_comms_every, Z=deepcopy(G), n_rewards=n_rewards, RM_iter=100, msg_threshold=msg_threshold, logger=print_output, fail_conidtion=attrition_time[i]))\n",
    "    elif mode == \"Global\":\n",
    "        robots.append(Global_AttritionGathering_Agent(initial_state=np.nan, initial_actions=deepcopy(initial_actions), initial_position=deepcopy(agents), i=i, n_agents=n_agents, gamma=gamma, c_p=c_p, budget=budget, planning_time=planning_time, N_components=N_components, N_com_every=N_comms_every, Z=deepcopy(G), n_rewards=n_rewards, logger=print_output, fail_conidtion=attrition_time[i]))\n",
    "    elif mode == \"Greedy\":\n",
    "        robots.append(Greedy_AttritionGathering_Agent(initial_state=np.nan, initial_actions=deepcopy(initial_actions), initial_position=deepcopy(agents), i=i, n_agents=n_agents, gamma=gamma, c_p=c_p, budget=budget, planning_time=planning_time, N_components=N_components, N_com_every=N_comms_every, Z=deepcopy(G), n_rewards=n_rewards, RM_iter=100, msg_threshold=msg_threshold, logger=print_output, fail_conidtion=attrition_time[i]))\n",
    "    elif mode == \"Reset\":\n",
    "        robots.append(Reset_AttritionGathering_Agent(initial_state=np.nan, initial_actions=deepcopy(initial_actions), initial_position=deepcopy(agents), i=i, n_agents=n_agents, gamma=gamma, c_p=c_p, budget=budget, planning_time=planning_time, N_components=N_components, N_com_every=N_comms_every, Z=deepcopy(G), n_rewards=n_rewards, logger=print_output, fail_conidtion=attrition_time[i]))\n",
    "\n",
    "# Set up shared information.\n",
    "shared_info.init()\n",
    "for robot in robots:\n",
    "    shared_info.global_pos[robot.index] = deepcopy(robot.position)\n",
    "    shared_info.global_distribution[robot.index] = deepcopy(robot.distribution)\n",
    "    shared_info.joint_path[robot.index] = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel planning and execution.\n",
    "for robot in robots:\n",
    "    robot.start()\n",
    "for robot in robots:\n",
    "    robot.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_paths = dict()\n",
    "for idx in shared_info.joint_path.keys():\n",
    "    if idx not in attrition_idx:\n",
    "        final_paths[idx] = shared_info.joint_path[idx]\n",
    "        print(idx, shared_info.joint_path[idx], G.evaluate_traj_cost(shared_info.joint_path[idx]))\n",
    "print(sum(G.evaluate_traj_reward(final_paths))/n_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(figsize=(10, 6))\n",
    "sns.set_theme(context='paper', style='whitegrid', palette='deep', font='Times New Roman', font_scale=2, color_codes=True, rc=None)\n",
    "path = dict()\n",
    "score = np.array([])\n",
    "\n",
    "max_iter = 0\n",
    "for robot in robots:\n",
    "    max_iter = max(max_iter, robot.iter)\n",
    "\n",
    "for i in range(max_iter):\n",
    "    for j in range(n_agents):\n",
    "        try:\n",
    "            path[j] = robots[j].rollout_history[i]\n",
    "        except:\n",
    "            pass\n",
    "    score = np.append(score, sum(G.evaluate_traj_reward(path))/len(rewards))\n",
    "ax = sns.lineplot(score)\n",
    "ax.set_xlim([0, max_iter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.style.use('seaborn-v0_8-white')\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "img = plt.imread(\"../../Data/config/map.jpg\")\n",
    "ax.imshow(img, extent=[0, 200, 0, 100])\n",
    "# Turn off tick labels\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])\n",
    "plt.xlim(0, 200)\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "current_pos = list()\n",
    "\n",
    "G.draw_agents([agents])\n",
    "\n",
    "# final_paths = dict()\n",
    "# final_paths[0] = [1, 1420, 16400]\n",
    "# final_paths[1] = [5, 5988, 3177]\n",
    "# final_paths[2] = [10, 13787, 11740, 17495]\n",
    "# final_paths[3] = [15, 22645, 4720, 6590]\n",
    "# final_paths[4] = [20, 34060, 7799]\n",
    "\n",
    "for key in final_paths.keys():\n",
    "    for i in range(len(final_paths[key])):\n",
    "        x_index = []\n",
    "        y_index = []\n",
    "        if ~np.isnan(final_paths[key][i]):\n",
    "            start_node = G.edges_list[int(final_paths[key][i])][0]\n",
    "            end_node = G.edges_list[int(final_paths[key][i])][1]\n",
    "            start_node_coor = G.find_coordinates(start_node)\n",
    "            end_node_coor = G.find_coordinates(end_node)\n",
    "            x_index.extend([start_node_coor[0], end_node_coor[0]])\n",
    "            y_index.extend([start_node_coor[1], end_node_coor[1]])\n",
    "            plt.plot(x_index, y_index, 'b', linewidth=3, solid_joinstyle='round', solid_capstyle='round')\n",
    "    dx = (end_node_coor[0] - start_node_coor[0])/100\n",
    "    dy = (end_node_coor[1] - start_node_coor[1])/100\n",
    "    plt.arrow(end_node_coor[0], end_node_coor[1], dx, dy, shape='full', lw=2, length_includes_head=True, head_width=2, color='b')\n",
    "\n",
    "for loc in locs:\n",
    "    if loc in rewards:\n",
    "        circle = plt.Circle((loc[0], loc[1]), 2.5, fc='none', ec='r', lw=1.5)\n",
    "        plt.gca().add_patch(circle)\n",
    "    plt.scatter(loc[0], loc[1], s=10, fc='gray')\n",
    "\n",
    "plt.draw()\n",
    "# fig.savefig(\"../../Figure/Oil_rigs.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate graph for oil rigs inspection.\n",
    "# from envs.prm import Euclindean_dist, SampleFree\n",
    "# import csv\n",
    "\n",
    "# def Near_radius(G, v, r):\n",
    "#     U = []\n",
    "#     for u in G.nodes.items():\n",
    "#         dist = Euclindean_dist(u[1], v)\n",
    "#         if dist >= 2 and dist <= r and (u[1][0] != v[0] or u[1][1] != v[1]):\n",
    "#             U.append(u)\n",
    "#     return np.array(U, dtype=object)\n",
    "\n",
    "# G = Graph(xL=0, xH=20, yL=0, yH=10, obsMask=np.array([[1,1,1,1,1,1,1,1,1],\n",
    "#                                                     [0,0,1,1,1,1,1,1,1],\n",
    "#                                                     [0,0,0,0,1,1,1,1,0],\n",
    "#                                                     [0,0,0,0,0,0,0,0,0],\n",
    "#                                                     [0,0,0,0,0,0,0,0,0],\n",
    "#                                                     [0,0,0,0,0,0,0,0,0],\n",
    "#                                                     [0,0,0,0,0,0,0,0,0]]), radius=0.25)\n",
    "\n",
    "# n_rewards = 1000\n",
    "\n",
    "# agents = [10, 7]\n",
    "# G.add_node(agents[0], agents[1])\n",
    "\n",
    "# locs = np.genfromtxt(\"../../Data/config/locs.csv\", delimiter=\",\")\n",
    "# rng = np.random.default_rng()\n",
    "# rewards = rng.choice(locs, size=n_rewards, replace=False)\n",
    "\n",
    "# n_nodes = 1000\n",
    "# nodes = SampleFree(n_nodes,\n",
    "#                     G.xL,\n",
    "#                     G.xH,\n",
    "#                     G.yL,\n",
    "#                     G.yH,\n",
    "#                     G, seed=np.random.randint(100))\n",
    "\n",
    "# for i in range(n_nodes):\n",
    "#     G.add_node(nodes[i][0], nodes[i][1])\n",
    "\n",
    "# for v in G.nodes.items():\n",
    "#     U = Near_radius(G, v[1], r=2.5)\n",
    "#     for u in U:\n",
    "#         G.add_edge(v[0], u[0], Euclindean_dist(u[1], v[1]), n_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from agent.Central_Agent import Central_InfoGathering_Agent\n",
    "\n",
    "# score = []\n",
    "# for i in range(20):\n",
    "#     # Add reward.\n",
    "#     rewards = rng.choice(locs, size=n_rewards, replace=False)\n",
    "#     G.reset_reward(n_rewards)\n",
    "#     G.add_reward(rewards)\n",
    "#     # Generate list of agents that will fail and the timestamp.\n",
    "#     attrition_idx = rng.choice(range(n_agents), size=int(n_agents*0.5), replace=False)\n",
    "\n",
    "#     # Create robots.\n",
    "#     initial_actions = []\n",
    "#     for j in range(len(G.edges_list)):\n",
    "#         if G.edges_list[j][0] == 0:\n",
    "#             initial_actions.append(j)\n",
    "\n",
    "#     actions_to_try = dict()\n",
    "#     for i in range(n_agents):\n",
    "#         actions_to_try[i] = deepcopy(initial_actions)\n",
    "\n",
    "#     robot = Central_InfoGathering_Agent(initial_state=np.nan, actions_to_try=actions_to_try, n_agents=n_agents, c_p=c_p, budget=200, planning_time=planning_time, Z=deepcopy(G), n_rewards=n_rewards)\n",
    "\n",
    "#     robot.planning()\n",
    "\n",
    "#     final_paths = dict()\n",
    "\n",
    "#     for i in range(n_agents):\n",
    "#         if i not in attrition_idx:\n",
    "#             final_paths[i] = robot.tree.data.at[0, 'best_rollout_path'][i]\n",
    "#     score.append(sum(G.evaluate_traj_reward(final_paths))/n_rewards)\n",
    "\n",
    "# for i in range(n_agents):\n",
    "#     path = robot.tree.data.at[0, 'best_rollout_path'][i]\n",
    "#     print(G.evaluate_traj_cost(path))\n",
    "\n",
    "# np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from envs.graph_helper import import_graph, parse\n",
    "# import csv\n",
    "# dir = \"../../../INFOCOM-24/Data\"\n",
    "# N_config = 10\n",
    "# N_trial = 2\n",
    "# algos = ['Dec', 'Central', 'Global', 'Greedy', 'Reset', 'RM']\n",
    "\n",
    "# df_cost = pd.DataFrame()\n",
    "\n",
    "# for config in range(N_config):\n",
    "#     G = Graph(-2, 2, -2, 2, 0.05)\n",
    "#     G, agents, rewards, nodes, _, n_nodes, _  = import_graph(G, \"{}/Config_{}\".format(dir, config))\n",
    "#     for trial in range(N_trial):\n",
    "#         for algo in algos:\n",
    "#             try:\n",
    "#                 cost = list()\n",
    "#                 with open(\"{}/9_action/action=9/{}-rollout-C{}-T{}.csv\".format(dir, algo, config, trial+1), 'r') as csv_file:\n",
    "#                     csv_reader = list(csv.reader(csv_file))\n",
    "#                     joint_path = parse(csv_reader[-1][0])\n",
    "\n",
    "#                 for path in joint_path.values():\n",
    "#                     cost.append(G.evaluate_traj_cost(path))\n",
    "#                 value = pd.DataFrame(data={'cost': cost, 'algo': [algo for _ in range(len(cost))]})\n",
    "#                 df_cost = pd.concat([df_cost, value], ignore_index=True)\n",
    "#             except:\n",
    "#                 pass\n",
    "# print(df_cost['cost'].mean(), df_cost['cost'].median())\n",
    "# sns.boxplot(data=df_cost, x='algo', y='cost')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decmcts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
